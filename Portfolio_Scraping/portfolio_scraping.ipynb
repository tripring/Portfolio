{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://watlab-blog.com/2019/08/10/chromedriver-path/\n",
    "# https://qiita.com/ti104110/items/c64f493eb6214b36add1\n",
    "# https://sushiringblog.com/chromedriver-error\n",
    "!pip3 install selenium\n",
    "!pip3 install beautifulsoup4\n",
    "# 使用する Google Chrome のバージョンに合う chromedriver をインストールする必要がある（以下のサイトから過去のバージョンを確認出来る）\n",
    "# https://pypi.org/project/chromedriver-binary/#history\n",
    "# !pip3 install chromedriver-binary==97.0.4692.71.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28cb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import chromedriver_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_seller_id( url, start, finish, directory ):\n",
    "    driver = get_driver()\n",
    "    for i in range( start, finish + 1 ):\n",
    "        print( \"商品検索 \" + str(i) + \" ページ目のデータを取得しています\" )\n",
    "        product_page_url_set = get_product_page_url_set( driver, url[: len( url ) - 2 ] + str( i ) )\n",
    "        for product_page_url in product_page_url_set:\n",
    "            print( \"セラーID を取得しています\" )\n",
    "            seller_id_set = get_seller_id_set( driver, product_page_url )\n",
    "            for seller_id in seller_id_set:\n",
    "                print( \"セラーID を 1件追加しました\" )\n",
    "                write_csv( directory + 'seller_id.csv', seller_id )\n",
    "                \n",
    "def scraping_seller_detail( directory ):\n",
    "    driver = get_driver()\n",
    "    print( \"セラーIDを取得しています\" )\n",
    "    with open( directory + 'seller_id.csv', encoding='utf8', newline='' ) as f:\n",
    "        csvreader = csv.reader( f )\n",
    "        for row in csvreader:\n",
    "            print( \"次の出品者の情報を取得しています\" )\n",
    "            write_csv_list( directory + 'seller_detail.csv', get_seller_detail( driver, row[0] ) )\n",
    "            print( \"1件の出品者の情報を csv に追加しました\" )\n",
    "    \n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    return webdriver.Chrome( options = options )\n",
    "\n",
    "def get_page_bs( driver, url ):\n",
    "    driver.get( url )\n",
    "    time.sleep( 10 ) # 10秒間待機\n",
    "    return BeautifulSoup( driver.page_source, features='lxml' )\n",
    "\n",
    "def get_product_page_url_set( driver, url ):\n",
    "    bs = get_page_bs( driver, url )\n",
    "    a_tags = bs.find_all( 'a', class_='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal' )\n",
    "    product_page_url_set = set( [] )\n",
    "    for item in a_tags:\n",
    "        product_page_url_set.add( \"https://www.amazon.co.jp/\" + item.get('href') )\n",
    "    return product_page_url_set\n",
    "\n",
    "def get_seller_id_set( driver, url ):\n",
    "    bs = get_page_bs( driver, url )\n",
    "    a_tags = bs.find_all('a')\n",
    "    seller_id_set = set([])\n",
    "    for item in a_tags:\n",
    "        s = item.get('href')\n",
    "        if ( type( s ) is str ) and ( 'seller=' in s ):\n",
    "            index = s.find( 'seller' )\n",
    "            if s[ index + 7 ] == 'A':\n",
    "                seller_id_set.add( s[ index + 7 : index + 21 ] )\n",
    "    return seller_id_set\n",
    "\n",
    "def get_seller_detail( driver, seller_id ):\n",
    "    seller_url = 'https://www.amazon.co.jp/sp?_encoding=UTF8&seller=' + seller_id\n",
    "    bs = get_page_bs( driver, seller_url )\n",
    "    datas = bs.find_all( 'div', class_ = 'a-row a-spacing-medium' )\n",
    "    if len( datas ) < 2:\n",
    "        return (\"\")\n",
    "    s = datas[1].text\n",
    "    ind1 = s.find(\"販売業者\")\n",
    "    ind2 = s.find(\"お問い合わせ先電話番号\")\n",
    "    ind3 = s.find(\"住所\")\n",
    "    ind4 = s.find(\"運営責任者名\")\n",
    "    ind5 = s.find(\"店舗名\")\n",
    "    p1 = \"\"\n",
    "    p2 = \"\"\n",
    "    if len(  bs.select('.feedback-detail-description') ) > 0:\n",
    "        point = bs.select('.feedback-detail-description')[0].text\n",
    "        p_ind1 = point.find(\"過去12ヵ月間で\")\n",
    "        p_ind2 = point.find(\"評価：\")\n",
    "        p1 = point[ : p_ind2 - 2 ]\n",
    "        p2 = point[ p_ind2 + 3: len( point ) - 1 ]\n",
    "    return ( seller_id, p1, p2, s[ind1+5:ind2].replace('\\n',''), s[ind2+12:ind3].replace('\\n',''), s[ind3+3:ind4].replace('\\n',''), s[ind4+7:ind5].replace('\\n',''), s[ind5+4:].replace('\\n',''), seller_url )\n",
    "\n",
    "def write_csv( file_path, data ):\n",
    "    with open( file_path, 'a' ) as f:\n",
    "        print( data, file = f )\n",
    "        \n",
    "def write_csv_list( file_path, data ):\n",
    "    with open( file_path, 'a' ) as f:\n",
    "        print( ','.join( data ), file=f )\n",
    "\n",
    "### 商品検索ページの URL， 検索ページの最初のページ， 検索ページの最後のページ， 出品者情報を保存するディレクトリ を指定してください###\n",
    "# u = \"https:// ~ \"\n",
    "u = \"https://www.amazon.co.jp/s?k=%E3%82%AB%E3%83%83%E3%83%97%E9%BA%BA&__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A&crid=1T20IHVWLAAXL&sprefix=%E3%82%AB%E3%83%83%E3%83%97%E9%BA%BA%2Caps%2C230&ref=nb_sb_noss_1\"\n",
    "# s = 1 \n",
    "s = 1\n",
    "# f = 10\n",
    "f = 10\n",
    "# d = \"scraping_data/\" #指定するディレクトリを事前に作成しておく必要があります\n",
    "d = \"data/\"\n",
    "### --- ###\n",
    "\n",
    "#scraping_seller_id( u, 1, 10, d )\n",
    "scraping_seller_detail( d )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
